{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module) :\n",
    "    expansion = 1\n",
    "    def __init__(self, in_channels, mid_channels, out_channels, stride = 1) :\n",
    "        super().__init__()\n",
    "        \n",
    "        self.residual_function = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size = 3, stride = stride, padding=1, bias = False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(mid_channels, out_channels * BasicBlock.expansion, kernel_size = 3, stride = 1, padding = 1, bias = False),\n",
    "            nn.BatchNorm2d(out_channels*BasicBlock.expansion),\n",
    "        )\n",
    "        self.shortcut = nn.Sequential()\n",
    "        \n",
    "        if stride != 1 or in_channels != BasicBlock.expansion * out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels * BasicBlock.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * BasicBlock.expansion)\n",
    "            )\n",
    "\n",
    "    def forward(self, x) :\n",
    "        return nn.ReLU(inplace=True)(self.residual_function(x) + self.shortcut(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block1_1 = BasicBlock(130, 256, 256)\n",
    "block1_2 = BasicBlock(256, 256, 256)\n",
    "conv1 = nn.Conv2d(in_channels = 256, out_channels = 256,  kernel_size = 3, stride = 1, padding = 1)\n",
    "maxpool = nn.MaxPool2d(kernel_size = (2,2), stride=(1,2), padding= (1,0))\n",
    "block2_1 = BasicBlock(256, 512, 256)\n",
    "# block2_2 = BasicBlock(512, 256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = block1_1(samp)\n",
    "print(x.shape)\n",
    "x = block1_2(x)\n",
    "print(x.shape)\n",
    "x = conv1(x)\n",
    "print(x.shape)\n",
    "x = maxpool(x)\n",
    "print(x.shape)\n",
    "x = block2_1(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = torch.rand((130,16,64)).unsqueeze(0)\n",
    "\n",
    "resblock2(resblock1(samp)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleResNet(nn.Module) :\n",
    "    def __init__(self, block, num_blocks, init_weights = True) :\n",
    "        super().__init__()\n",
    "        self.in_channels = 130\n",
    "        self.block1 = self._make_layer(block, 256, 256, num_blocks[0])\n",
    "        self.conv1 = nn.Conv2d(self.in_channels, out_channels = self.in_channels, kernel_size= 3, padding = 1)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size = (2, 2), stride = (2,1), padding = (0,1))\n",
    "        self.block2 = self._make_layer(block, 256, 512, num_blocks[1])\n",
    "        self.conv2 = nn.Conv2d(self.in_channels, out_channels = self.in_channels, kernel_size = 3, padding = 1)\n",
    "        self.block3 = self._make_layer(block, 512, 512, num_blocks[2])\n",
    "        self.conv3 = nn.Conv2d(self.in_channels, out_channels = self.in_channels, kernel_size = 2, stride = (2,1), padding = (0,1))\n",
    "        self.conv4 = nn.Conv2d(self.in_channels, out_channels = self.in_channels, kernel_size = 2, stride = (1,1), padding = (0,0))\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size = (3,1), stride = (2,1), padding = (0,0))\n",
    "        \n",
    "        if init_weights :\n",
    "            self._initialize_weights()\n",
    "    \n",
    "    def _make_layer(self, block, mid_channels, out_channels, num_blocks, stride = 1) :\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides :\n",
    "            layers.append(block(self.in_channels, mid_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels\n",
    "            \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    \n",
    "    def forward(self, x) :\n",
    "        output = self.block1(x)\n",
    "        output = self.conv1(output)\n",
    "        output = self.maxpool(output)\n",
    "        output = self.block2(output)\n",
    "        output = self.conv2(output)\n",
    "        output = self.block3(output)\n",
    "        output = self.conv3(output)\n",
    "        output = self.conv4(output)\n",
    "        output = self.avgpool(output)\n",
    "        return output\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_net = SimpleResNet(BasicBlock, [2,5,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([53, 512, 1, 65])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp = torch.randn(([53, 130, 16, 64]))\n",
    "\n",
    "samp_net(samp).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = samp_net.block1(samp)\n",
    "x = samp_net.conv1(x)\n",
    "\n",
    "x = samp_net.maxpool(x)\n",
    "x = samp_net.block2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resnet_list = list(resnet.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0 \n",
    "for bottleneck in resnet_list :\n",
    "    if isinstance(bottleneck, nn.Sequential) :\n",
    "        i+= 1\n",
    "        print(bottleneck)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "resnet = torchvision.models.resnet.resnet50(pretrained=True)\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Helper module that consists of a Conv -> BN -> ReLU\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, padding=1, kernel_size=3, stride=1, with_nonlinearity=True):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, padding=padding, kernel_size=kernel_size, stride=stride)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.with_nonlinearity = with_nonlinearity\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        if self.with_nonlinearity:\n",
    "            x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Bridge(nn.Module):\n",
    "    \"\"\"\n",
    "    This is the middle layer of the UNet which just consists of some\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.bridge = nn.Sequential(\n",
    "            ConvBlock(in_channels, out_channels),\n",
    "            ConvBlock(out_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.bridge(x)\n",
    "\n",
    "\n",
    "class UpBlockForUNetWithResNet50(nn.Module):\n",
    "    \"\"\"\n",
    "    Up block that encapsulates one up-sampling step which consists of Upsample -> ConvBlock -> ConvBlock\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, up_conv_in_channels=None, up_conv_out_channels=None,\n",
    "                 upsampling_method=\"conv_transpose\"):\n",
    "        super().__init__()\n",
    "\n",
    "        if up_conv_in_channels == None:\n",
    "            up_conv_in_channels = in_channels\n",
    "        if up_conv_out_channels == None:\n",
    "            up_conv_out_channels = out_channels\n",
    "\n",
    "        if upsampling_method == \"conv_transpose\":\n",
    "            self.upsample = nn.ConvTranspose2d(up_conv_in_channels, up_conv_out_channels, kernel_size=2, stride=2)\n",
    "        elif upsampling_method == \"bilinear\":\n",
    "            self.upsample = nn.Sequential(\n",
    "                nn.Upsample(mode='bilinear', scale_factor=2),\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1)\n",
    "            )\n",
    "        self.conv_block_1 = ConvBlock(in_channels, out_channels)\n",
    "        self.conv_block_2 = ConvBlock(out_channels, out_channels)\n",
    "\n",
    "    def forward(self, up_x, down_x):\n",
    "        \"\"\"\n",
    "        :param up_x: this is the output from the previous up block\n",
    "        :param down_x: this is the output from the down block\n",
    "        :return: upsampled feature map\n",
    "        \"\"\"\n",
    "        x = self.upsample(up_x)\n",
    "        x = torch.cat([x, down_x], 1)\n",
    "        x = self.conv_block_1(x)\n",
    "        x = self.conv_block_2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class UNetWithResnet50Encoder(nn.Module):\n",
    "    DEPTH = 6\n",
    "\n",
    "    def __init__(self, n_classes=4):\n",
    "        super().__init__()\n",
    "        resnet = torchvision.models.resnet.resnet50(pretrained=True)\n",
    "        down_blocks = []\n",
    "        up_blocks = []\n",
    "        self.input_block = nn.Sequential(*list(resnet.children()))[:3]\n",
    "        self.input_pool = list(resnet.children())[3]\n",
    "        for bottleneck in list(resnet.children()):\n",
    "            if isinstance(bottleneck, nn.Sequential):\n",
    "                down_blocks.append(bottleneck)\n",
    "        self.down_blocks = nn.ModuleList(down_blocks)\n",
    "        self.bridge = Bridge(2048, 2048)\n",
    "        up_blocks.append(UpBlockForUNetWithResNet50(2048, 1024))\n",
    "        up_blocks.append(UpBlockForUNetWithResNet50(1024, 512))\n",
    "        up_blocks.append(UpBlockForUNetWithResNet50(512, 256))\n",
    "        up_blocks.append(UpBlockForUNetWithResNet50(in_channels=128 + 64, out_channels=128,\n",
    "                                                    up_conv_in_channels=256, up_conv_out_channels=128))\n",
    "        up_blocks.append(UpBlockForUNetWithResNet50(in_channels=64 + 3, out_channels=64,\n",
    "                                                    up_conv_in_channels=128, up_conv_out_channels=64))\n",
    "\n",
    "        self.up_blocks = nn.ModuleList(up_blocks)\n",
    "\n",
    "        self.out = nn.Conv2d(64, n_classes, kernel_size=1, stride=1)\n",
    "\n",
    "    def forward(self, x, with_output_feature_map=True):\n",
    "        pre_pools = dict()\n",
    "        pre_pools[f\"layer_0\"] = x\n",
    "        x = self.input_block(x)\n",
    "        pre_pools[f\"layer_1\"] = x\n",
    "        x = self.input_pool(x)\n",
    "\n",
    "        for i, block in enumerate(self.down_blocks, 2):\n",
    "            x = block(x)\n",
    "            if i == (UNetWithResnet50Encoder.DEPTH - 1):\n",
    "                continue\n",
    "            pre_pools[f\"layer_{i}\"] = x\n",
    "\n",
    "        x = self.bridge(x)\n",
    "\n",
    "        for i, block in enumerate(self.up_blocks, 1):\n",
    "            key = f\"layer_{UNetWithResnet50Encoder.DEPTH - 1 - i}\"\n",
    "            if i == UNetWithResnet50Encoder.DEPTH - 1 :\n",
    "                output_feature_map = x\n",
    "            x = block(x, pre_pools[key])\n",
    "        \n",
    "        x = self.out(x)\n",
    "        del pre_pools\n",
    "        if with_output_feature_map:\n",
    "            return x, output_feature_map\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "model = UNetWithResnet50Encoder().cuda()\n",
    "inp = torch.rand((2, 3, 512, 512)).cuda()\n",
    "out = model(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "down_blocks = []\n",
    "\n",
    "for bottleneck in resnet_list :\n",
    "    if isinstance(bottleneck, nn.Sequential) :\n",
    "        down_blocks.append(bottleneck)\n",
    "        \n",
    "for i, block in enumerate(down_blocks, 2) :\n",
    "    if i == (UNetWithResnet50Encoder.DEPTH - 1):\n",
    "        continue\n",
    "    print(block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(resnet.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual_Block(nn.Module): \n",
    "    def __init__(self, in_dim, mid_dim, out_dim): \n",
    "        super(Residual_Block,self).__init__() # Residual Block \n",
    "        self.residual_block = nn.Sequential( nn.Conv2d(in_dim, mid_dim, kernel_size=3, padding=1), \n",
    "                                            nn.ReLU(), \n",
    "                                            nn.Conv2d(mid_dim, out_dim, kernel_size=3, padding=1), ) \n",
    "        self.relu = nn.ReLU() \n",
    "    \n",
    "    def forward(self, x): \n",
    "        out = self.residual_block(x) # F(x) out = out + x # F(x) + x \n",
    "        out = self.relu(out) \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rblock = Residual_Block(256, 256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Up block that encapsulates one up-sampling step which consists of Upsample -> ConvBlock -> ConvBlock\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, up_conv_in_channels=None, up_conv_out_channels=None,\n",
    "                 upsampling_method=\"conv_transpose\"):\n",
    "        super().__init__()\n",
    "\n",
    "        if up_conv_in_channels == None:\n",
    "            up_conv_in_channels = in_channels\n",
    "        if up_conv_out_channels == None:\n",
    "            up_conv_out_channels = out_channels\n",
    "\n",
    "        if upsampling_method == \"conv_transpose\":\n",
    "            self.upsample = nn.ConvTranspose2d(up_conv_in_channels, up_conv_out_channels, kernel_size=2, stride=2)\n",
    "        elif upsampling_method == \"bilinear\":\n",
    "            self.upsample = nn.Sequential(\n",
    "                nn.Upsample(mode='bilinear', scale_factor=2),\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1)\n",
    "            )\n",
    "        self.conv_block_1 = ConvBlock(in_channels, out_channels)\n",
    "        self.conv_block_2 = ConvBlock(out_channels, out_channels)\n",
    "\n",
    "    def forward(self, up_x, down_x):\n",
    "        \"\"\"\n",
    "        :param up_x: this is the output from the previous up block\n",
    "        :param down_x: this is the output from the down block\n",
    "        :return: upsampled feature map\n",
    "        \"\"\"\n",
    "        x = self.upsample(up_x)\n",
    "        x = torch.cat([x, down_x], 1)\n",
    "        x = self.conv_block_1(x)\n",
    "        x = self.conv_block_2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BottleNeck(nn.Module):\n",
    "    expansion = 4\n",
    "    def __init__(self, in_channels, out_channels, stride=2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.residual_function = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels * BottleNeck.expansion, kernel_size=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels * BottleNeck.expansion),\n",
    "        )\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        if stride != 1 or in_channels != out_channels * BottleNeck.expansion:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels*BottleNeck.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels*BottleNeck.expansion)\n",
    "            )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.residual_function(x) + self.shortcut(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class Bridge(nn.Module):\n",
    "    \"\"\"\n",
    "    This is the middle layer of the UNet which just consists of some\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.bridge = nn.Sequential(\n",
    "            ConvBlock(in_channels, out_channels),\n",
    "            ConvBlock(out_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.bridge(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpBlock(nn.Module) :\n",
    "    def __init__(self, input_channel, output_channel, upsampling_method = 'conv_transpose') :\n",
    "        super().__init__()\n",
    "        if upsampling_method == \"conv_transpose\":\n",
    "            self.UpSample = nn.ConvTranspose2d(input_channel, input_channel, kernel_size=2, stride=2)\n",
    "        elif upsampling_method == \"bilinear\":\n",
    "            self.UpSample = nn.Sequential(\n",
    "                nn.Upsample(mode='bilinear', scale_factor=2),\n",
    "                nn.Conv2d(input_channel, input_channel, kernel_size=1, stride=1)\n",
    "            )\n",
    "\n",
    "        self.UpConv_Block = nn.Sequential(\n",
    "                                            nn.Conv2d(input_channel*2, output_channel*2, kernel_size = 1, stride = 1),\n",
    "                                            nn.BatchNorm2d(output_channel*2),\n",
    "                                            nn.ReLU(),\n",
    "                                            nn.Conv2d(output_channel*2, output_channel, kernel_size = 3, stride = 1, padding = 1),\n",
    "                                            nn.BatchNorm2d(output_channel),\n",
    "                                            nn.ReLU()            \n",
    "                                            )\n",
    "    \n",
    "    def forward(self, up_x, down_x, return_output = False) :\n",
    "        x = self.UpSample(up_x)\n",
    "        x = torch.cat([x, down_x], 1)\n",
    "        if return_output :\n",
    "            output_feature = x\n",
    "        x = self.UpConv_Block(x)\n",
    "        if return_output :\n",
    "            return x, output_feature\n",
    "        else :\n",
    "            return x\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottleneck_1 = BottleNeck(3, 16)\n",
    "\n",
    "bottleneck_1(torch.rand(1,3,128,128)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetUNet(nn.Module) :\n",
    "    def __init__(self, input_channel, n_classes) :\n",
    "        super().__init__()\n",
    "        self.input_channel = input_channel\n",
    "        self.down_block1 = BottleNeck(self.input_channel, 16)\n",
    "        self.down_block2 = BottleNeck(64, 64)\n",
    "        self.down_block3 = BottleNeck(256, 128)\n",
    "        self.down_block4 = BottleNeck(512, 256)\n",
    "        self.down_block5 = BottleNeck(1024, 512)\n",
    "        self.bridge = nn.ConvTranspose2d(2048, 1024, kernel_size=1, stride=1)\n",
    "        \n",
    "        self.up_block1 = UpBlock(1024, 512)\n",
    "        self.up_block2 = UpBlock(512, 256)\n",
    "        self.up_block3 = UpBlock(256, 64)\n",
    "        self.up_block4 = UpBlock(64, 32)\n",
    "        self.last_layer = nn.Sequential(\n",
    "                                       nn.Conv2d(32,32, kernel_size= 3, stride = 1, padding = 1),\n",
    "                                       nn.Conv2d(32,32, kernel_size= 3, stride = 1, padding = 1),\n",
    "                                       nn.Conv2d(32,16, kernel_size= 3, stride = 1, padding = 1),\n",
    "                                       nn.Conv2d(16,16, kernel_size= 1),\n",
    "                                       nn.Conv2d(16,n_classes, kernel_size = 1, stride = 1)\n",
    "                                      )\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        pre_pools = dict()\n",
    "        x = self.down_block1(x)\n",
    "        print(x.shape)\n",
    "        pre_pools[f\"layer_1\"] = x\n",
    "        x = self.down_block2(x)\n",
    "        print(x.shape)\n",
    "        pre_pools[f\"layer_2\"] = x\n",
    "        x = self.down_block3(x)\n",
    "        print(x.shape)\n",
    "        pre_pools[f\"layer_3\"] = x\n",
    "        x = self.down_block4(x) \n",
    "        print(x.shape)\n",
    "        pre_pools[f\"layer_4\"] = x\n",
    "        x = self.down_block5(x) \n",
    "        print(x.shape)\n",
    "        x = self.bridge(x)\n",
    "        print(x.shape)\n",
    "        x = self.up_block1(x, pre_pools['layer_4'])\n",
    "        print(x.shape)\n",
    "        x = self.up_block2(x, pre_pools['layer_3'])\n",
    "        print(x.shape)\n",
    "        x = self.up_block3(x, pre_pools['layer_2'])\n",
    "        print(x.shape)\n",
    "        x, output_feature = self.up_block4(x, pre_pools['layer_1'], return_output = True)\n",
    "        print(x.shape)\n",
    "        x = self.last_layer(x)\n",
    "             \n",
    "        return x, output_feature\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 256, 256])\n",
      "torch.Size([1, 256, 128, 128])\n",
      "torch.Size([1, 512, 64, 64])\n",
      "torch.Size([1, 1024, 32, 32])\n",
      "torch.Size([1, 2048, 16, 16])\n",
      "torch.Size([1, 1024, 16, 16])\n",
      "torch.Size([1, 512, 32, 32])\n",
      "torch.Size([1, 256, 64, 64])\n",
      "torch.Size([1, 64, 128, 128])\n",
      "torch.Size([1, 32, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sampnet = ResNetUNet(3, 4)\n",
    "\n",
    "x, output_feature = sampnet(torch.rand(1,3,512,512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 256, 256])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.cat([x[:,:2,:,:], output_feature], 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ResUnet import CRAFT\n",
    "import torch\n",
    "net = CRAFT(input_channel = 3, n_classes = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "768/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = torch.randn((1,3,768,768))\n",
    "\n",
    "x, output_feature = net(samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 384, 384])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 384, 384])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
